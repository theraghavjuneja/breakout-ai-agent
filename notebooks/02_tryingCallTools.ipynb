{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "@tool\n",
    "def multiply(a:int,b:int)->int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a*b\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This @tool decorator is the simplest way to define a custom tool. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. This @tool decorator is the simplest way to define a custom tool. The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as a param to tool (input schema), one can also add annotations, nested schems and  other features too\n",
    "from typing import Annotated,List\n",
    "@tool\n",
    "def multiply_by_max(\n",
    "    a: Annotated[str, \"scale factor\"],\n",
    "    b: Annotated[List[int], \"list of ints over which to take maximum\"],\n",
    ") -> int:\n",
    "    \"\"\"Multiply a by the maximum of b.\"\"\"\n",
    "    return a * max(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiply_by_max\n"
     ]
    }
   ],
   "source": [
    "print(multiply_by_max.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiply a by the maximum of b.\n"
     ]
    }
   ],
   "source": [
    "print(multiply_by_max.description)\n",
    "# print(multiply.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': {'title': 'A', 'type': 'string'}, 'b': {'title': 'B', 'type': 'array', 'items': {'type': 'integer'}}}\n"
     ]
    }
   ],
   "source": [
    "print(multiply_by_max.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multiplication-tool\n",
      "Multiply two numbers.\n",
      "{'a': {'title': 'A', 'description': 'first number', 'type': 'integer'}, 'b': {'title': 'B', 'description': 'second number', 'type': 'integer'}}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# as such aap input m ek json schema ya [pydantic ] bhi de skte ho\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "# by default tool ka naam whi hota \n",
    "# jo function ka naam hai jiske upar @ decorator lga hai\n",
    "# otherwise khud se spcify name like here I did \n",
    "@tool(\"multiplication-tool\", args_schema=CalculatorInput, return_direct=True)\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "# Let's inspect some of the attributes associated with the tool.\n",
    "print(multiply.name)\n",
    "print(multiply.description)\n",
    "print(multiply.args)\n",
    "print(multiply.return_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "async def amultiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "calculator = StructuredTool.from_function(func=multiply, coroutine=amultiply)\n",
    "\n",
    "print(calculator.invoke({\"a\": 2, \"b\": 3}))\n",
    "print(await calculator.ainvoke({\"a\": 2, \"b\": 5}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Retrieval-augmented generation\n",
      "Summary: Retrieval Augmented Generation (RAG) is a technique that grants generative artificial intelligence models information retrieval capabilities. It modifies interactions with a large language model (LLM) so that the model responds to user queries with reference to a specified set of documents, using this information to augment information drawn from its own vast, static training data. This allows LLMs to use domain-specific and/or updated information.  \n",
      "Use cases include providing chatbot access to internal company data or giving factual information only from an authoritative source.\n",
      "\n",
      "\n",
      "\n",
      "Page: DataStax\n",
      "Summary: DataStax, Inc. is a real-time data for AI company based in Santa Clara, California. Its product Astra DB is a cloud database-as-a-service based on Apache Cassandra. DataStax also offers DataStax Enterprise (DSE), an on-premises database built on Apache Cassandra, and Astra Streaming, a messaging and event streaming cloud service based on Apache Pulsar. As of June 2022, the company has roughly 800 customers distributed in over 50 countries.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "api_wrapper=WikipediaAPIWrapper()\n",
    "tool=WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "print(tool.run({\"query\":\"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-flash-latest\",temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatGroq(model=\"llama-3.1-8b-instant\",temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "tool=load_tools([\"wikipedia\"],llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent=initialize_agent(tool,llm,agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to find information about \"llama\" as a large language model (LLM).  Wikipedia should be a good resource for this.\n",
      "\n",
      "Action: wikipedia\n",
      "Action Input: LLaMA (large language model)\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mPage: Llama (language model)\n",
      "Summary: Llama (Large Language Model Meta AI, formerly stylized as LLaMA) is a family of autoregressive large language models (LLMs) released by Meta AI starting in February 2023. The latest version is Llama 3.2, released in September 2024.\n",
      "Model weights for the first version of Llama were made available to the research community under a non-commercial license, and access was granted on a case-by-case basis. Unauthorized copies of the model were shared via BitTorrent. In response, Meta AI issued DMCA takedown requests against repositories sharing the link on GitHub. Subsequent versions of Llama were made accessible outside academia and released under licenses that permitted some commercial use. Llama models are trained at different parameter sizes, ranging between 1B and 405B. Originally, Llama was only available as a foundation model. Starting with Llama 2, Meta AI started releasing instruction fine-tuned versions alongside foundation models.\n",
      "Alongside the release of Llama 3, Meta added virtual assistant features to Facebook and WhatsApp in select regions, and a standalone website. Both services use a Llama 3 model.\n",
      "\n",
      "Page: Large language model\n",
      "Summary: A large language model (LLM) is a type of computational model designed for natural language processing tasks such as language generation. As language models, LLMs acquire these abilities by learning statistical relationships from vast amounts of text during a self-supervised and semi-supervised training process.\n",
      "The largest and most capable LLMs are artificial neural networks built with a decoder-only transformer-based architecture, enabling efficient processing and generation of large-scale text data. Modern models can be fine-tuned for specific tasks, or be guided by prompt engineering. These models acquire predictive power regarding syntax, semantics, and ontologies inherent in human language corpora, but they also inherit inaccuracies and biases present in the data on which they are trained.\n",
      "\n",
      "Page: Language model\n",
      "Summary: A language model is a probabilistic model of a natural language. In 1980, the first significant statistical language model was proposed, and during the decade IBM performed ‘Shannon-style’ experiments, in which potential sources for language modeling improvement were identified by observing and analyzing the performance of human subjects in predicting or correcting text.\n",
      "Language models are useful for a variety of tasks, including speech recognition (helping prevent predictions of low-probability (e.g. nonsense) sequences), machine translation, natural language generation (generating more human-like text), optical character recognition, route optimization, handwriting recognition, grammar induction, and information retrieval.\n",
      "Large language models, currently their most advanced form, are a combination of larger datasets (frequently using words scraped from the public internet), feedforward neural networks, and transformers. They have superseded recurrent neural network-based models, which had previously superseded the pure statistical models, such as word n-gram language model.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer.\n",
      "Final Answer: LLaMA (Large Language Model Meta AI) is a family of large language models (LLMs) created by Meta AI.\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LLaMA (Large Language Model Meta AI) is a family of large language models (LLMs) created by Meta AI.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"what is llama and who create this llm model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above thing works good,\n",
    "# as the mentioned says it will search inside wikipedia for this informati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.weatherapi.com/',\n",
       "  'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.775, 'lon': -122.4183, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1731848824, 'localtime': '2024-11-17 05:07'}, 'current': {'last_updated_epoch': 1731848400, 'last_updated': '2024-11-17 05:00', 'temp_c': 8.3, 'temp_f': 46.9, 'is_day': 0, 'condition': {'text': 'Clear', 'icon': '//cdn.weatherapi.com/weather/64x64/night/113.png', 'code': 1000}, 'wind_mph': 3.1, 'wind_kph': 5.0, 'wind_degree': 124, 'wind_dir': 'SE', 'pressure_mb': 1019.0, 'pressure_in': 30.08, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 80, 'cloud': 0, 'feelslike_c': 7.8, 'feelslike_f': 46.1, 'windchill_c': 12.0, 'windchill_f': 53.6, 'heatindex_c': 11.8, 'heatindex_f': 53.2, 'dewpoint_c': 8.4, 'dewpoint_f': 47.1, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 0.0, 'gust_mph': 5.0, 'gust_kph': 8.0}}\"},\n",
       " {'url': 'https://www.timeanddate.com/weather/usa/san-francisco/hourly',\n",
       "  'content': 'Hour-by-Hour Forecast for San Francisco, California, USA. Time/General. Weather. Time Zone. DST Changes. Sun & Moon. Weather Today Weather Hourly 14 Day Forecast Yesterday/Past Weather Climate (Averages) Currently: 63 °F. Scattered clouds.'},\n",
       " {'url': 'https://www.timeanddate.com/weather/@z-us-94141',\n",
       "  'content': 'Time Zone News Calendar & Holiday News Time Zones Time Zones Home Time Zone Converter Time Zone Map Time Changes Worldwide Time Zone News Weather Moon Calculator Calculators Calculators Home Home \\xa0 Weather \\xa0 San Francisco Weather Time Zone Weather TodayWeather Hourly14 Day ForecastYesterday/Past WeatherClimate (Averages) Forecast: 60 / 43\\xa0°F Location:San Francisco International AirportCurrent Time:Nov 15, 2024 at 5:01:38 pmLatest Report:Nov 15, 2024 at 3:56 pmVisibility:10\\xa0miPressure:29.96 \"HgHumidity:60%Dew Point:43\\xa0°F Forecast for the next 48 hours ↑ | | * Updated Friday, November 15, 2024 11:03:03 am San Francisco time - Weather by CustomWeather, © 2024 | 14 day forecast, day-by-dayHour-by-hour forecast for next week More weather last week Sun & Moon times precise to the second. Time Zones Weather Calculators'},\n",
       " {'url': 'https://world-weather.info/forecast/usa/san_francisco/november-2024/',\n",
       "  'content': 'Extended weather forecast in San Francisco. Hourly Week 10-Day 14-Day 30-Day Year. Detailed ⚡ San Francisco Weather Forecast for November 2024 - day/night 🌡️ temperatures, precipitations - World-Weather.info.'},\n",
       " {'url': 'https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41965999999996',\n",
       "  'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056°NLon: 122.42694°WElev: 150.0ft. NA. 58°F. 14°C. ... 07:00am until November 17, 01:00pm. High Surf Advisory November 14, 07:00am until November 16, 11:00am ... National Weather Service; San Francisco Bay Area, CA; 21 Grace Hopper Ave, Stop 5; Monterey, CA 93943-5505; Comments'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is the weather in SF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[search]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Charanjeet Juneja\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    }
   ],
   "source": [
    "prompt=hub.pull(\"hwchase17/openai-functions-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "agent_scratchpad: The agent does not call a tool just once to get the desired answer, but has a structure that calls tools repeatedly until the desired answer is obtained. Each time you call a tool, what the previous call was like, information about the previous call, and the result are stored in this field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "agent = create_tool_calling_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'Zomato contact email addresses legal support interview'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m[{'url': 'https://www.moneycontrol.com/company-facts/zomato/management/Z', 'content': 'Get Zomato contact details, Registered Address of Zomato along with Zomato management information. ... Interview Series Business In The Week Ahead ... Email: companysecretary@zomato.com'}, {'url': 'https://www.grievanceofficer.com/grievance-officer-zomato/', 'content': 'Grievance Officer at Zomato - Grievance Officer Grievance Officer Grievance Officers You are here: Home / Grievance Officer at Zomato Grievance Officer at Zomato Grievance Redressal Officer Email address: legal@zomato.com Grievance Redressal Officer Email address: legal@zomato.com my order value is ₹700 But zomato team says they cant do anyting and they said they can only waive of ₹30 later ₹300, here we are suffering here food is nt warm either the restaurents are not charged pwnalty fees. AR on Grievance Officer at OnePlus India Sanketha on Grievance Officer at Flipkart suresh babu on Grievance Officer at Flipkart Man Singh on Grievance Officer at MakeMyTrip arun sharma on Grievance Officer at Flipkart Vajinder Kumar on Grievance Officer at Flipkart'}, {'url': 'https://www.lexisandcompany.com/2024/04/title-advocating-consumer-rights-filing.html', 'content': \"If you've encountered issues with Zomato's services and are considering raising a complaint, understanding the process for filing complaints with consumer forums is essential. At Lexis and Company, we provide legal guidance and support to consumers navigating disputes with businesses like Zomato, empowering them to assert their rights and seek\"}, {'url': 'https://www.zomato.com/policies/terms-of-service/', 'content': '15. Call Recording: Zomato may contact Zomato Gold members via telephone, SMS or other electronic messaging or by email with information about your Zomato Gold experience or any feedback thereon. Any calls that may be made by Zomato, by itself or through a third party, to the members or the restaurant pertaining to the experience of a Customer'}, {'url': 'https://www.ambitionbox.com/interviews/zomato-interview-questions/customer-service-executive', 'content': 'Updated 20 Jun 2024. Top Zomato Customer Service Executive Interview Questions and Answers. Q1. How u deal to the customer if he get non veg food instead of veg food ? View answers (31) Q2. How you deal to the customer if he complain that delivery boy threaten him ? View answers (7) Q3.'}]\u001b[0m\u001b[32;1m\u001b[1;3mBased on the search results, it appears that Zomato's contact email addresses for purposes like legal, support, and interview are:\n",
      "\n",
      "* companysecretary@zomato.com\n",
      "* legal@zomato.com\n",
      "\n",
      "Please note that these email addresses may be subject to change, and it's always best to check Zomato's official website or contact their customer support for the most up-to-date information.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats are the multiple mail addresses through which I can contact Zomato for purposes like legal, support, and interview?',\n",
       " 'output': \"Based on the search results, it appears that Zomato's contact email addresses for purposes like legal, support, and interview are:\\n\\n* companysecretary@zomato.com\\n* legal@zomato.com\\n\\nPlease note that these email addresses may be subject to change, and it's always best to check Zomato's official website or contact their customer support for the most up-to-date information.\"}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats are the multiple mail addresses through which I can contact Zomato for purposes like legal, support, and interview?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI am sorry, I cannot fulfill this request. The available tools lack the desired functionality.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats the weather in sf?',\n",
       " 'output': 'I am sorry, I cannot fulfill this request. The available tools lack the desired functionality.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats the weather in sf?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
